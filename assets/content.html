<h2><span style="color: #3366ff;">Confusion Matrix</span></h2>
<p>On the left you can see the confusion matrix taken from the test set containing 1629 test samples. A confusion matrix summarizes the comparison of the predicted labels of the Test set to the actual true label of the test set. The diagonal blue squares show that for the most part, the predicted label is relatively accurate.</p>
<p>It also helps quickly visualize how much of each type you have to train on. You can easily tell that I have many more images for d6 and d20 dice. If I were to exapand the data, it would be good practice try not to have too many of one category.</p>
==
<h2><span style="color: #3366ff;">Model Layers</span></h2>
<p>On the left you can see a graph of the model that is predicting the images above. This particular model represents a sequential <strong>convolutional neural network</strong> interleaved with<strong> pooling</strong> layers that reduce spacial dimentions to help the model learn important features of the image. The pixel input for the image is <strong>(448,448,3)</strong> When you import your own image, this application will need to reduuce it to those dimensions before the model can predict on it. The flatten layer squishes down the <strong>3D array</strong> to a <strong>1D array</strong> to prepare it before using the last dense layer to make a prediction of one of the 6 categories [d4,d6,d8,d10,d12,d20]</p>
==
<h2><span style="color: #3366ff;">Model Training<br /></span></h2>
<p>Below is a visualizaiton of the epochs from when the model was trained. Epochs are like rounds of training. Notice how the accuracy shoots up from ~78% to ~95% after the second Epoch and starts to plateau around the 5th Epoch at 97%. While this is great for the model, the real perfomance metric is the validation accuracy and loss, labeled val_accuracy and val_loss. This shows how the model will perform on data it's never seen before. For most loss functions, the lower number the better. 0.5 is good, but it definitely could be improved.</p>